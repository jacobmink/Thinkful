{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   In this project, I download Yelp reviews, isolate the star value and text of each review, clean the text, split the dataset into folds, build a RandomForest model, and attempt to predict star values of a testing set using text as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3 as lite\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "import collections\n",
    "import json\n",
    "import ijson\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Download the Yelp Data Challenge dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.yelp.com/dataset_challenge/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset from first 25,000 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_size = 25000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset contains ~2.2 million reviews. For the purpose of this project, I used 25,000 of these reviews. The data is structured as a file where each line is a separate JSON file, so  the following code reads each JSON file in separately. In order to simplify this analysis, I created a binary classification structure where reviews with < 3 stars become 0 stars, and reviews with > 3 stars become 1 star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "data_test = []\n",
    "y = []\n",
    "X = []\n",
    "with open('yelp_academic_dataset_review.json','rU') as reviews:\n",
    "    i = 0\n",
    "    while i < sample_size:\n",
    "        first_line = json.loads(reviews.readline())\n",
    "        if first_line['stars'] != 3:\n",
    "            if first_line['stars'] < 3:\n",
    "                first_line['stars'] = 0\n",
    "            else:\n",
    "                first_line['stars'] = 1\n",
    "            data.append([first_line['stars'], first_line['text']])\n",
    "            y.append(first_line['stars'])\n",
    "            X.append(first_line['text'])\n",
    "        i += 1\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text for Bag-of-Words:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following block is a text-cleaning function. It spits out a bag of words representing the input without puncuation, capitalization, or any overly common words (the, a, is, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def review_to_words(raw_review):\n",
    "    #     1) Remove HTML:\n",
    "    review_text = BeautifulSoup(raw_review).get_text()\n",
    "    #     2) Remove non-letters:\n",
    "    letters_only = re.sub('[^a-zA-Z]',' ', review_text)\n",
    "    #     3) Convert to lower case, split into words:\n",
    "    words = letters_only.lower().split()\n",
    "    #     4) Convert stopwords to set:\n",
    "    stops = set(stopwords.words('english'))\n",
    "    #     5) Remove stopwords:\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    #     6) Join words back into one string separated by space:\n",
    "    return( ' '.join(meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20963"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_reviews = X.size\n",
    "num_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the Yelp reviews...\n",
      "\n",
      "Review 1000 of 20963\n",
      "\n",
      "Review 2000 of 20963\n",
      "\n",
      "Review 3000 of 20963\n",
      "\n",
      "Review 4000 of 20963\n",
      "\n",
      "Review 5000 of 20963\n",
      "\n",
      "Review 6000 of 20963\n",
      "\n",
      "Review 7000 of 20963\n",
      "\n",
      "Review 8000 of 20963\n",
      "\n",
      "Review 9000 of 20963\n",
      "\n",
      "Review 10000 of 20963\n",
      "\n",
      "Review 11000 of 20963\n",
      "\n",
      "Review 12000 of 20963\n",
      "\n",
      "Review 13000 of 20963\n",
      "\n",
      "Review 14000 of 20963\n",
      "\n",
      "Review 15000 of 20963\n",
      "\n",
      "Review 16000 of 20963\n",
      "\n",
      "Review 17000 of 20963\n",
      "\n",
      "Review 18000 of 20963\n",
      "\n",
      "Review 19000 of 20963\n",
      "\n",
      "Review 20000 of 20963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Cleaning and parsing the Yelp reviews...\\n\"\n",
    "clean_reviews = []\n",
    "for i in xrange(0, num_reviews):\n",
    "    if (i+1)%1000 == 0:\n",
    "        print \"Review %d of %d\\n\" % (i+1,num_reviews)\n",
    "    clean_reviews.append(review_to_words(X[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_reviews = np.array(clean_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'Creating the bag of words...\\n'\n",
    "vectorizer = CountVectorizer(analyzer='word',\n",
    "                             tokenizer=None,\n",
    "                             preprocessor=None,\n",
    "                             stop_words=None,\n",
    "                             max_features=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the data into folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(y, n_folds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on vectorized training text, generate RandomForest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "Testing using the random forest...\n",
      "PRECISION: 0.889216263995 RECALL: 0.960534691279 F1 SCORE: 0.923500611995 CONFUSION MATRIX: [[ 338  188]\n",
      " [  62 1509]]\n",
      "Training the random forest...\n",
      "Testing using the random forest...\n",
      "PRECISION: 0.88340034463 RECALL: 0.978994271165 F1 SCORE: 0.928743961353 CONFUSION MATRIX: [[ 323  203]\n",
      " [  33 1538]]\n",
      "Training the random forest...\n",
      "Testing using the random forest...\n",
      "PRECISION: 0.898224852071 RECALL: 0.966263526416 F1 SCORE: 0.93100275989 CONFUSION MATRIX: [[ 354  172]\n",
      " [  53 1518]]\n",
      "Training the random forest...\n",
      "Testing using the random forest...\n",
      "PRECISION: 0.888436955259 RECALL: 0.973265436028 F1 SCORE: 0.928918590522 CONFUSION MATRIX: [[ 334  192]\n",
      " [  42 1529]]\n",
      "Training the random forest...\n",
      "Testing using the random forest...\n",
      "PRECISION: 0.880571428571 RECALL: 0.980903882877 F1 SCORE: 0.928033724782 CONFUSION MATRIX: [[ 317  209]\n",
      " [  30 1541]]\n",
      "Training the random forest...\n",
      "Testing using the random forest...\n",
      "PRECISION: 0.889148191365 RECALL: 0.970082749841 F1 SCORE: 0.927853881279 CONFUSION MATRIX: [[ 336  190]\n",
      " [  47 1524]]\n",
      "Training the random forest...\n",
      "Testing using the random forest...\n",
      "PRECISION: 0.887143688191 RECALL: 0.971337579618 F1 SCORE: 0.927333536029 CONFUSION MATRIX: [[ 332  194]\n",
      " [  45 1525]]\n",
      "Training the random forest...\n",
      "Testing using the random forest...\n",
      "PRECISION: 0.878285714286 RECALL: 0.97898089172 F1 SCORE: 0.925903614458 CONFUSION MATRIX: [[ 312  213]\n",
      " [  33 1537]]\n",
      "Training the random forest...\n",
      "Testing using the random forest...\n",
      "PRECISION: 0.892441860465 RECALL: 0.977707006369 F1 SCORE: 0.933130699088 CONFUSION MATRIX: [[ 340  185]\n",
      " [  35 1535]]\n",
      "Training the random forest...\n",
      "Testing using the random forest...\n",
      "PRECISION: 0.887357699221 RECALL: 0.943312101911 F1 SCORE: 0.914479777709 CONFUSION MATRIX: [[ 337  188]\n",
      " [  89 1481]]\n"
     ]
    }
   ],
   "source": [
    "precision_list = []\n",
    "recall_list = []\n",
    "output_list = []\n",
    "f1_score_list = []\n",
    "confusion_list = []\n",
    "for train, test in skf:\n",
    "#     Partition the data\n",
    "    X_train, X_test = clean_reviews[train], clean_reviews[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "#     Fit model and learn features, transform into vectors\n",
    "    data_features_train = vectorizer.fit_transform(X_train)\n",
    "    data_features_train = data_features_train.toarray()\n",
    "#     Transform test data into vectors\n",
    "    data_features_test = vectorizer.transform(X_test)\n",
    "    data_features_test = data_features_test.toarray()\n",
    "    print 'Training the random forest...'\n",
    "#     Train RandomForest on training data\n",
    "    forest = forest.fit(data_features_train, y_train)\n",
    "\n",
    "#     Try to predict using RandomForest model\n",
    "    print 'Testing using the random forest...'\n",
    "    result = forest.predict(data_features_test)\n",
    "#     Statistical analysis for each fold\n",
    "    precision = metrics.precision_score(y_test,result)\n",
    "    precision_list.append(precision)\n",
    "    recall = metrics.recall_score(y_test,result)\n",
    "    recall_list.append(recall)\n",
    "    f1_score = metrics.f1_score(y_test,result)\n",
    "    f1_score_list.append(f1_score)\n",
    "    confusion = metrics.confusion_matrix(y_test,result)\n",
    "    confusion_list.append(confusion)\n",
    "\n",
    "    print 'PRECISION:', precision, 'RECALL:', recall, 'F1 SCORE:', f1_score, 'CONFUSION MATRIX:', confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18868, 5000)"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate statistics on each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN PRECISION: 0.887422699805\n",
      "STD PRECISION: 0.00543863227911\n",
      "MEAN RECALL: 0.970138213722\n",
      "STD RECALL: 0.0108069938289\n",
      "MEAN F1 SCORE: 0.92689011571\n",
      "STD F1 SCORE 0.0048199781492\n",
      "CONFUSION MATRIX LIST: [array([[ 338,  188],\n",
      "       [  62, 1509]]), array([[ 323,  203],\n",
      "       [  33, 1538]]), array([[ 354,  172],\n",
      "       [  53, 1518]]), array([[ 334,  192],\n",
      "       [  42, 1529]]), array([[ 317,  209],\n",
      "       [  30, 1541]]), array([[ 336,  190],\n",
      "       [  47, 1524]]), array([[ 332,  194],\n",
      "       [  45, 1525]]), array([[ 312,  213],\n",
      "       [  33, 1537]]), array([[ 340,  185],\n",
      "       [  35, 1535]]), array([[ 337,  188],\n",
      "       [  89, 1481]])]\n"
     ]
    }
   ],
   "source": [
    "mean_precision = np.mean(precision_list)\n",
    "mean_recall = np.mean(recall_list)\n",
    "mean_f1 = np.mean(f1_score_list)\n",
    "std_precision = np.std(precision_list)\n",
    "std_recall = np.std(recall_list)\n",
    "std_f1 = np.std(f1_score_list)\n",
    "print 'MEAN PRECISION:', mean_precision\n",
    "print 'STD PRECISION:', std_precision\n",
    "print 'MEAN RECALL:', mean_recall\n",
    "print 'STD RECALL:', std_recall\n",
    "print 'MEAN F1 SCORE:', mean_f1\n",
    "print 'STD F1 SCORE', std_f1\n",
    "print 'CONFUSION MATRIX LIST:', confusion_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Average precision of 89%, average recall of 97%, overall f1 score of 92%\n",
    "- Based on these stats, I would say this model did a fairly reasonable job predicting the test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
